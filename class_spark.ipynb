{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PRODUCT CATEGORY CLASSIFICATION**\n",
    "\n",
    "### Here, we want to develop an automatic and scalable first prototipe that helps to correctly categorize a new product in the available categories when it arrives.\n",
    "\n",
    "This first prototipe will help us to identify in what elements we have to go deeper in order to get the best model.\n",
    "\n",
    "\n",
    "https://towardsdatascience.com/multi-class-text-classification-with-pyspark-7d78d022ed35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summary of requirements**\n",
    "\n",
    "1. Train a model that predicts the product category for Software, Digital Software, and\n",
    "Digital Video Games products using the Amazon Customer Reviews dataset.\n",
    "2. Evaluate and validate your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I checked warnings, but for the final report I prefer ignore those \n",
    "#that really does not affect the results (warnings of libraries, etc)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my own functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.py_functions import *\n",
    "from utils.cleaning_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load all the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in /home/erikapat/anaconda3/lib/python3.7/site-packages (1.5.0)\n",
      "Requirement already satisfied: pillow in /home/erikapat/anaconda3/lib/python3.7/site-packages (from wordcloud) (6.1.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /home/erikapat/anaconda3/lib/python3.7/site-packages (from wordcloud) (1.17.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud \n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create spark session and provide master as yarn-client and provide application name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration properties of Apache Spark\n",
    "#sc.stop()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = 'pyspark_python'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME)\n",
    "conf = conf.setMaster(MASTER)\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schema = StructType([\n",
    "    StructField(\"marketplace\",  StringType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"product_id\",  StringType(), True),\n",
    "    StructField(\"product_parent\", IntegerType(), True),\n",
    "    StructField(\"product_title\", StringType(), True),\n",
    "    StructField(\"product_category\", StringType(), True),\n",
    "    StructField(\"star_rating\", IntegerType(), True),\n",
    "    StructField(\"helpful_votes\", IntegerType(), True),\n",
    "    StructField(\"total_votes\", IntegerType(), True),\n",
    "    StructField(\"vine\", StringType(), True),\n",
    "    StructField(\"verified_purchase\", StringType(), True),\n",
    "    StructField(\"review_headline\", StringType(), True),\n",
    "    StructField(\"review_body\", StringType(), True),\n",
    "    StructField(\"review_date\", StringType(), True)])\n",
    "'''\n",
    "df_video_games = spark.read\\\n",
    "    .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "    .option(\"delimiter\",\",\")\\\n",
    "    .option(\"inferSchema\", \"True\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .load('data/amazon_reviews_us_Digital_Video_Games_v1_00.tsv')\n",
    "'''\n",
    "\n",
    "df_video_games = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Digital_Video_Games_v1_00.tsv')\n",
    "\n",
    "df_software = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Software_v1_00.tsv')\n",
    "\n",
    "df_digital_software = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Digital_Software_v1_00.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MERGE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_digital_software.union(df_software);\n",
    "df = df.union(df_video_games);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
      "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|        review_date|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
      "|         US|   17747349|R2EI7QLPK4LF7U|B00U7LCE6A|     106182406|CCleaner Free [Do...|Digital_Software|          4|            0|          0|   N|                Y|          Four Stars|      So far so good|2015-08-31 00:00:00|\n",
      "|         US|   10956619|R1W5OMFK1Q3I3O|B00HRJMOM4|     162269768|ResumeMaker Profe...|Digital_Software|          3|            0|          0|   N|                Y|         Three Stars|Needs a little mo...|2015-08-31 00:00:00|\n",
      "|         US|   13132245| RPZWSYWRP92GI|B00P31G9PQ|     831433899|Amazon Drive Desk...|Digital_Software|          1|            1|          2|   N|                Y|            One Star|      Please cancel.|2015-08-31 00:00:00|\n",
      "|         US|   35717248|R2WQWM04XHD9US|B00FGDEPDY|     991059534|Norton Internet S...|Digital_Software|          5|            0|          0|   N|                Y|  Works as Expected!|  Works as Expected!|2015-08-31 00:00:00|\n",
      "|         US|   17710652|R1WSPK2RA2PDEF|B00FZ0FK0U|     574904556|SecureAnywhere In...|Digital_Software|          4|            1|          2|   N|                Y|Great antivirus. ...|I've had Webroot ...|2015-08-31 00:00:00|\n",
      "|         US|   42392705|R11JVGRZRHTDAS|B004KPKSRQ|     306022575|Pc Matic Performa...|Digital_Software|          5|            4|          4|   N|                N|Great choice in s...|EXCELLENT softwar...|2015-08-31 00:00:00|\n",
      "|         US|   52845868|R2B8468OKXXYE2|B00B1TFNTW|      54873662|Microsoft OneNote...|Digital_Software|          1|            1|          1|   N|                N|Munch, munch, mun...|The variations cr...|2015-08-31 00:00:00|\n",
      "|         US|   15696503|R2HGGCCZSSNUCB|B00M9GTJLY|     103182180|Intuit Quicken Re...|Digital_Software|          1|            0|          0|   N|                Y|Horrible! Would n...|Horrible!  Would ...|2015-08-31 00:00:00|\n",
      "|         US|    9723928| REEE4LHSVPRV9|B00H9A60O4|     608720080|Avast Free Antivi...|Digital_Software|          1|            0|          0|   N|                Y|            One Star|     Waste of time .|2015-08-31 00:00:00|\n",
      "|         US|   23522877|R25OMUUILFFHI9|B008XAXAC4|      87969525|Apache OpenOffice...|Digital_Software|          5|            0|          0|   N|                Y|Very good suite o...|Work as easy as o...|2015-08-31 00:00:00|\n",
      "|         US|   17022093|R2966PB8UBD5BM|B00MHZ6Z64|     249773946|     Norton Security|Digital_Software|          5|            0|          0|   N|                Y|          Five Stars|    Works perfectly!|2015-08-31 00:00:00|\n",
      "|         US|   11635690|R1OU91L2G5H6H1|B00OPCQ70Q|     956532818|Corel Painter Ess...|Digital_Software|          1|            0|          2|   N|                Y|            One Star|Will not open on ...|2015-08-31 00:00:00|\n",
      "|         US|   50349059|R3M6YQVMXWGTR6|B00MHZ71G2|       8655796|Norton Security w...|Digital_Software|          5|            0|          0|   N|                Y|Purchased this on...|Purchased this on...|2015-08-31 00:00:00|\n",
      "|         US|     450121|R2M8VZGO4BFN9J|B00O8J0W6G|       7338419|Movavi Screen Cap...|Digital_Software|          1|            0|          1|   N|                Y|            One Star|God awful and did...|2015-08-31 00:00:00|\n",
      "|         US|    2320642|R3UH0MJKIJ4VLP|B00NMPZCH6|     985055699|Photoshop Element...|Digital_Software|          3|            2|          3|   N|                Y|         Three Stars|I think its compl...|2015-08-31 00:00:00|\n",
      "|         US|   16089737|R3E906WYGZVKWO|B012P5SJNC|     490456974|LearnSmart for Th...|Digital_Software|          1|            2|          2|   N|                Y|Will not work for...|You can purchase ...|2015-08-31 00:00:00|\n",
      "|         US|   14082044|R1Z3N8UA5YQOV2|B00V9ZPIXY|      57097904|Fotor for Windows...|Digital_Software|          2|            0|          0|   N|                Y|           Two Stars|    it wont download|2015-08-31 00:00:00|\n",
      "|         US|   18246272|R2VH10XSOR1QHF|B00LU2XHAC|     962800663|Kaspersky Anti-Vi...|Digital_Software|          5|            0|          0|   N|                Y|          Five Stars|I have been using...|2015-08-31 00:00:00|\n",
      "|         US|   31837971|R1KCPJ8UASZESF|B0068TJOSQ|     154476766|H&R Block At Home...|Digital_Software|          5|            0|          0|   N|                Y|This was a Great ...|This was a Great ...|2015-08-31 00:00:00|\n",
      "|         US|   12631500| RWTF87EKV4DYO|B00SGYWM80|     780881648| onlineTV [Download]|Digital_Software|          3|            0|          0|   N|                Y|         Three Stars|did not use,inter...|2015-08-31 00:00:00|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+----------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnames = ['marketplace', 'customer_id',  'product_id',\\n       'product_parent', 'product_title', 'product_category', 'star_rating',\\n       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\\n       'review_headline', 'review_body', 'review_date'] #'review_id'\\ndf_x = df.toDF(*names)\\ndf_x.toPandas().head()\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "names = ['marketplace', 'customer_id',  'product_id',\n",
    "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
    "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "       'review_headline', 'review_body', 'review_date'] #'review_id'\n",
    "df_x = df.toDF(*names)\n",
    "df_x.toPandas().head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Top 20 PRODUCTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------+-----+\n",
      "|product_title                                            |count|\n",
      "+---------------------------------------------------------+-----+\n",
      "|Playstation Network Card                                 |13642|\n",
      "|Avast Free Antivirus 2015 [Download]                     |9470 |\n",
      "|TurboTax Deluxe Fed + Efile + State                      |8965 |\n",
      "|Xbox Live Subscription                                   |7307 |\n",
      "|Playstation Plus Subscription                            |4712 |\n",
      "|Quicken Deluxe 20                                        |4020 |\n",
      "|TurboTax Deluxe Federal + E-File + State 2012            |3831 |\n",
      "|Turbo Tax Parent V2                                      |3708 |\n",
      "|Block Financial H&R Block Tax Software 14 Deluxe + State |3682 |\n",
      "|TurboTax Deluxe Fed, Efile and State 2013                |3658 |\n",
      "|Xbox Live Gift Card                                      |3438 |\n",
      "|SimCity - Limited Edition                                |3421 |\n",
      "|Norton 360 1 User 3 Licenses                             |3213 |\n",
      "|Xbox 360 Live Points Card                                |3036 |\n",
      "|Quicken Deluxe Personal Finance & Budgeting Software 2015|2924 |\n",
      "|TurboTax Premier Fed + Efile + State                     |2608 |\n",
      "|Norton 360 2013 - 1 User / 3 PC                          |2581 |\n",
      "|Microsoft Office Home and Student 2007 [Old Version]     |2521 |\n",
      "|Quicken Deluxe 2013                                      |2478 |\n",
      "|Microsoft Windows 8 Pro - Upgrade [Old Version]          |2104 |\n",
      "+---------------------------------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from pyspark.sql.functions import col\n",
    "df.groupBy(\"product_title\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|review_headline|count|\n",
      "+---------------+-----+\n",
      "|Five Stars     |46735|\n",
      "|Four Stars     |9027 |\n",
      "|One Star       |7578 |\n",
      "|Three Stars    |4261 |\n",
      "|Two Stars      |2415 |\n",
      "|Great          |1603 |\n",
      "|Great Product  |1588 |\n",
      "|Great product  |1308 |\n",
      "|Excellent      |1012 |\n",
      "|Great game     |998  |\n",
      "|Awesome        |897  |\n",
      "|Great Game     |856  |\n",
      "|great          |733  |\n",
      "|Easy to use    |714  |\n",
      "|Good           |688  |\n",
      "|Disappointed   |676  |\n",
      "|Great!         |670  |\n",
      "|Good product   |621  |\n",
      "|good           |550  |\n",
      "|Love it        |543  |\n",
      "+---------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"review_headline\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|review_body  |count|\n",
      "+-------------+-----+\n",
      "|good         |948  |\n",
      "|Good         |931  |\n",
      "|Great        |861  |\n",
      "|great        |602  |\n",
      "|Excellent    |559  |\n",
      "|ok           |457  |\n",
      "|Perfect      |275  |\n",
      "|excellent    |256  |\n",
      "|Great!       |244  |\n",
      "|Awesome      |243  |\n",
      "|very good    |240  |\n",
      "|Nice         |237  |\n",
      "|Very good    |234  |\n",
      "|love it      |230  |\n",
      "|Ok           |212  |\n",
      "|Great product|211  |\n",
      "|Thanks       |198  |\n",
      "|Love it      |188  |\n",
      "|Great game   |159  |\n",
      "|nice         |158  |\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"review_body\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DROP DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+----------------+--------------------+\n",
      "|     review_id|       product_title|product_category|         review_body|\n",
      "+--------------+--------------------+----------------+--------------------+\n",
      "|R2EI7QLPK4LF7U|CCleaner Free [Do...|Digital_Software|      So far so good|\n",
      "|R1W5OMFK1Q3I3O|ResumeMaker Profe...|Digital_Software|Needs a little mo...|\n",
      "| RPZWSYWRP92GI|Amazon Drive Desk...|Digital_Software|      Please cancel.|\n",
      "|R2WQWM04XHD9US|Norton Internet S...|Digital_Software|  Works as Expected!|\n",
      "|R1WSPK2RA2PDEF|SecureAnywhere In...|Digital_Software|I've had Webroot ...|\n",
      "|R11JVGRZRHTDAS|Pc Matic Performa...|Digital_Software|EXCELLENT softwar...|\n",
      "|R2B8468OKXXYE2|Microsoft OneNote...|Digital_Software|The variations cr...|\n",
      "|R2HGGCCZSSNUCB|Intuit Quicken Re...|Digital_Software|Horrible!  Would ...|\n",
      "| REEE4LHSVPRV9|Avast Free Antivi...|Digital_Software|     Waste of time .|\n",
      "|R25OMUUILFFHI9|Apache OpenOffice...|Digital_Software|Work as easy as o...|\n",
      "+--------------+--------------------+----------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['marketplace', 'customer_id',  'product_id',\n",
    "       'product_parent', 'star_rating',\n",
    "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "        'review_date', 'review_headline'] #,'review_id',, 'review_body'\n",
    "df = df.select([column for column in df.columns if column not in drop_list])\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- product_title: string (nullable = true)\n",
      " |-- product_category: string (nullable = true)\n",
      " |-- review_body: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ELIMINATE DUPLICATED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(589446, 4)\n",
      "(37354, 4)\n"
     ]
    }
   ],
   "source": [
    "#So, we eliminate them\n",
    "print(df.toPandas().shape)\n",
    "df = df.dropDuplicates(subset= ['product_title', 'product_category'])\n",
    "print(df.toPandas().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+-------------------+--------------------+\n",
      "|     review_id|       product_title|   product_category|         review_body|\n",
      "+--------------+--------------------+-------------------+--------------------+\n",
      "| RP4MUWMW5PDMH|2014 World Book M...|           Software|available for win...|\n",
      "| RLXRY2WDMC7F1|2017 TKT Payroll ...|           Software|It say 2015 but t...|\n",
      "| RUBVRR7OYC2VG|4 Step Loan Modif...|           Software|I would like to f...|\n",
      "|R167B987XQ467P|900 Vector Art De...|           Software|             Exelent|\n",
      "|R31TIOVO2HIPC7|A Love of Art 3 C...|           Software|If you're looking...|\n",
      "|R1OPMK9DQ1MF3U|ACCPAC INTERNATIO...|           Software|Will not run on m...|\n",
      "|R2IIPA0W00VQV5|ACT! Pro v16 Soft...|           Software|Delivered on time...|\n",
      "|R3LJECXTVSR7EX|ASA 2014 Airframe...|           Software|               Ismok|\n",
      "|R2H6ZULQI27QXH|Adobe Acrobat 6.0...|           Software|This version does...|\n",
      "|R3VKJWMSO23TLF|Adobe CS6 Master ...|           Software|Works great excel...|\n",
      "|R2QZP016IBUTK4|Adobe InDesign CS5.5|           Software|Very happy with m...|\n",
      "|R23H6310S8KJBM|Adobe Photoshop E...|   Digital_Software|download it sever...|\n",
      "|R2Q710GCMO6BZJ|Adventures In Ody...|           Software|My son enjoyed pl...|\n",
      "|R1C7U4ZT24DAYP|Airbus X Extended...|           Software|This one of the b...|\n",
      "|R2HJUFDQV5VG2N|Airline Tycoon De...|           Software|This game is a gr...|\n",
      "|R2PW6SQ6I8UAYA|Airport Firefight...|Digital_Video_Games|hey its a grate g...|\n",
      "|R1EN4N456G4T7X|      Amplitube Live|           Software|I was looking for...|\n",
      "|R1CC9NKB6GRF9L|Anime Studio Pro ...|           Software|Great software, I...|\n",
      "|R2DS349D7EAP2C|Anime Studio Pro 9.5|           Software|I loved it. it wa...|\n",
      "|R3J556IGFITLKW|Appleworks 6.2.7 ...|           Software|I ordered the ver...|\n",
      "+--------------+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **COMPLETE MISSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.review_body.fillna(df.product_title, inplace=True)\n",
    "df=spark.createDataFrame(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NUMERICAL VARIABLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our list of functions to apply.\n",
    "transform_functions = [\n",
    "    lambda x: len(x),\n",
    "    lambda x: x.count(\" \"),\n",
    "    lambda x: x.count(\".\"),\n",
    "    lambda x: x.count(\"!\"),\n",
    "    lambda x: x.count(\"?\"),\n",
    "    lambda x: len(x) / (x.count(\" \") + 1),\n",
    "    lambda x: x.count(\" \") / (x.count(\".\") + 1),\n",
    "    lambda x: len(re.findall(\"CD|DVD\", x)), # CD \n",
    "    lambda x: len(re.findall(r\"\\d+st|\\d+th|\\d+sd\", x)), # th--> 4th, 5th or 1st or 2sd\n",
    "    lambda x: len(re.findall(\"[A-Z]\", x)), # number of uppercase letters\n",
    "    lambda x: len(re.findall(\"[0-9]\", x)), #numbers\n",
    "    lambda x: len(re.findall(\"\\d{4}\", x)),\n",
    "    lambda x: len(re.findall(\"\\d$\", x)), #end with number\n",
    "    lambda x: len(re.findall(\"^\\d\", x)), #start with number\n",
    "    lambda x: len(re.findall(\"[\\w]+-[\\w]+\",x)), #words separated with -\n",
    "    lambda x: len(re.findall(\"OLD VERSION|Old Version|old version\",x)), #old version\n",
    "]\n",
    "\n",
    "transform_functions_len = [\n",
    "    lambda x: len(x)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_2 = df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num = df_num_2[['product_title']]\n",
    "df_num_2 = df_num_2[['review_id']]\n",
    "for func in transform_functions:\n",
    "     df_num_2 = pd.concat([df_num_2, df_num['product_title'].apply(func)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_2.columns = ['review_id', 'title_len', 'title_words', 'title_points',\n",
    "                  'title_exc', 'title_int', 'ratio_spaces_point', 'ratio_len_points', \n",
    "                    'title_cd','title_th', 'title_upper_letters', 'title_numbers',\n",
    "                    'title_years', 'end_number', 'starts_number', 'word_sep', \n",
    "                  'title_old_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>title_len</th>\n",
       "      <th>title_words</th>\n",
       "      <th>title_points</th>\n",
       "      <th>title_exc</th>\n",
       "      <th>title_int</th>\n",
       "      <th>ratio_spaces_point</th>\n",
       "      <th>ratio_len_points</th>\n",
       "      <th>title_cd</th>\n",
       "      <th>title_th</th>\n",
       "      <th>title_upper_letters</th>\n",
       "      <th>title_numbers</th>\n",
       "      <th>title_years</th>\n",
       "      <th>end_number</th>\n",
       "      <th>starts_number</th>\n",
       "      <th>word_sep</th>\n",
       "      <th>title_old_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>RP4MUWMW5PDMH</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>RLXRY2WDMC7F1</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.571429</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RUBVRR7OYC2VG</td>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>R167B987XQ467P</td>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>R31TIOVO2HIPC7</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_id  title_len  title_words  title_points  title_exc  title_int  \\\n",
       "0   RP4MUWMW5PDMH         46            6             0          0          0   \n",
       "1   RLXRY2WDMC7F1         46            6             0          0          0   \n",
       "2   RUBVRR7OYC2VG         50            8             0          0          0   \n",
       "3  R167B987XQ467P         68           12             0          0          0   \n",
       "4  R31TIOVO2HIPC7         39            8             0          0          0   \n",
       "\n",
       "   ratio_spaces_point  ratio_len_points  title_cd  title_th  \\\n",
       "0            6.571429               6.0         1         0   \n",
       "1            6.571429               6.0         0         0   \n",
       "2            5.555556               8.0         0         0   \n",
       "3            5.230769              12.0         0         0   \n",
       "4            4.333333               8.0         1         0   \n",
       "\n",
       "   title_upper_letters  title_numbers  title_years  end_number  starts_number  \\\n",
       "0                    7              4            1           0              1   \n",
       "1                    7              4            1           0              1   \n",
       "2                    7              1            0           0              1   \n",
       "3                   11              4            0           0              1   \n",
       "4                   11              1            0           0              0   \n",
       "\n",
       "   word_sep  title_old_version  \n",
       "0         0                  0  \n",
       "1         0                  0  \n",
       "2         0                  0  \n",
       "3         1                  0  \n",
       "4         1                  0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CLEAN DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_title_cleaning(df):\n",
    "    #eliminate contractions I'm -> I am\n",
    "    df_X = df.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], fix_abbreviation(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #consider only noums in the text\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], tag_and_remove(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #lemmatization\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], lemitizeWords(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "\n",
    "    #clean text\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], clean_text(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #spelling correction\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], spell_correction(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|review_id     |product_category   |product_title                                                                                                                                                                           |review_body                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "+--------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|RP4MUWMW5PDMH |Software           |2014 World Book Multimedia Encyclopedia on DVD                                                                                                                                          |windows mac                                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|RLXRY2WDMC7F1 |Software           |2017 TKT Payroll Software for Small Businesses                                                                                                                                          |form print data program website                                                                                                                                                                                                                                                                                                                                               |\n",
      "|RUBVRR7OYC2VG |Software           |4 Step Loan Modification Software - Do It Yourself                                                                                                                                      |i reviewer individual product product sale book guarantee money guarantee which claims rate reductions loan modification software product assistance pc introduction software borrowers modifications bonus trial version link inside trial version version one sale home version thanks developer                                                                            |\n",
      "|R167B987XQ467P|Software           |900 Vector Art Designs Volume 1 - Sign Vinyl T-Shirt Vector Clip Art                                                                                                                    |exedent                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|R31TIOVO2HIPC7|Software           |A Love of Art 3 CD-ROM Set (Jewel Case)                                                                                                                                                 |software time eggery era art set that taste painting town year period something about sense art town images software money worth                                                                                                                                                                                                                                              |\n",
      "|R1OPMK9DQ1MF3U|Software           |ACCPAC INTERNATIONAL Simply ACCOUNTING 8.0                                                                                                                                              |system                                                                                                                                                                                                                                                                                                                                                                        |\n",
      "|R2IIPA0W00VQV5|Software           |ACT! Pro v16 Software by Swiftpage - 1 License - (2014 - NEWEST VERSION)                                                                                                                |time installation integration window outlook                                                                                                                                                                                                                                                                                                                                  |\n",
      "|R3LJECXTVSR7EX|Software           |ASA 2014 Airframe Test Guide Book (ASA-AMA-14)                                                                                                                                          |smoke                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|R2H6ZULQI27QXH|Software           |Adobe Acrobat 6.0 Standard                                                                                                                                                              |version windows                                                                                                                                                                                                                                                                                                                                                               |\n",
      "|R3VKJWMSO23TLF|Software           |Adobe CS6 Master Collection MAC OS                                                                                                                                                      |works group programs                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|R2QZP016IBUTK4|Software           |Adobe InDesign CS5.5                                                                                                                                                                    |purchase i i book nice price company good                                                                                                                                                                                                                                                                                                                                     |\n",
      "|R23H6310S8KJBM|Digital_Software   |Adobe Photoshop Extended CS6                                                                                                                                                            |download times problems support team trial potshop website conf number trial trial fingers trial                                                                                                                                                                                                                                                                              |\n",
      "|R2Q710GCMO6BZJ|Software           |Adventures In Odyssey: Sword of the Spirit                                                                                                                                              |son game wife i life lessons etc claims game kids it something one                                                                                                                                                                                                                                                                                                            |\n",
      "|R1C7U4ZT24DAYP|Software           |Airbus X Extended Edition Windows PC                                                                                                                                                    |a a adion fix there failures simulation a a                                                                                                                                                                                                                                                                                                                                   |\n",
      "|R2HJUFDQV5VG2N|Software           |Airline Tycoon Deluxe                                                                                                                                                                   |game time waster while campaigns i style goal companies business game get flights freight money staff competitors buy stock buy offices fix planes planes reputation advertising                                                                                                                                                                                              |\n",
      "|R2PW6SQ6I8UAYA|Digital_Video_Games|Airport Firefighter Simulator 2013 EN (MULTILINGUAL) [Download]                                                                                                                         |grate game windows but clot                                                                                                                                                                                                                                                                                                                                                   |\n",
      "|R1EN4N456G4T7X|Software           |Amplitube Live                                                                                                                                                                          |i amp simulator garageman stock guitar sounds i trial amp settings bass amp i i something i lexicon lambda interface mac ideas fuss tone garageman latency trial period i deal amplitude live thought i disappointment boatload preset sounds i tones sounding trial version live latency delay bit i garageman support documentation bottom line money matter deal bucks deal|\n",
      "|R1CC9NKB6GRF9L|Software           |Anime Studio Pro 9 - MotionArtist - Morpheus Photo Animation Suite - 3 Software Titles for the Price of 1! Mac and PC Versions included!                                                |software i step step                                                                                                                                                                                                                                                                                                                                                          |\n",
      "|R2DS349D7EAP2C|Software           |Anime Studio Pro 9.5                                                                                                                                                                    |i it studio characters game maker studio game engine                                                                                                                                                                                                                                                                                                                          |\n",
      "|R3J556IGFITLKW|Software           |Appleworks 6.2.7 - CD Set-int [OLD VERSION]                                                                                                                                             |i version pileworks pc version apple computer i informed software pc wrong i years i cd jak                                                                                                                                                                                                                                                                                   |\n",
      "|R3A4ULRJLZFWRF|Software           |Art Explosion 300,000, DVD                                                                                                                                                              |images styles today all image list tedious                                                                                                                                                                                                                                                                                                                                    |\n",
      "|R3PG6B183F17FX|Software           |Atari Greatest Hits Atari Arcade Hits 2 Pack                                                                                                                                            |disc time favorites disc                                                                                                                                                                                                                                                                                                                                                      |\n",
      "|R665L8EQVVW62 |Software           |Automatic Driver Recovery for Lenovo ThinkPad SL500 & Complete All Drivers with One-Click Installer; Internet, Wi-Fi, Ethernet, Video, Sound, Audio, USB, Devices, ...(Restore Disc/Disk|work waste time drivers product                                                                                                                                                                                                                                                                                                                                               |\n",
      "|RTS6747HH2VNK |Software           |Avid Liquid Vs 7 Upgrade                                                                                                                                                                |editing software i i the cut liquid word caution separate disc storage create media render folder assign file management system manages do files product titles fcp hey effects                                                                                                                                                                                               |\n",
      "|R19SU629MYPVX8|Software           |Bionicle                                                                                                                                                                                |biocycle series games products biocycle series                                                                                                                                                                                                                                                                                                                                |\n",
      "+--------------+-------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = product_title_cleaning(df)\n",
    "df.show(25, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopppp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6fcaac1a8906>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopppp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stopppp' is not defined"
     ]
    }
   ],
   "source": [
    "stopppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "df = df.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  clean_text(x[\"product_title\"]), x[\"review_body\"]))\n",
    "df=spark.createDataFrame(df, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate columns\n",
    "\n",
    "from pyspark.sql.functions import concat, col, lit\n",
    "col_list = ['product_title','review_body']\n",
    "df = df.withColumn('product_title',concat(*col_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+--------------------+--------------------+\n",
      "|     review_id|product_category|       product_title|         review_body|\n",
      "+--------------+----------------+--------------------+--------------------+\n",
      "| RP4MUWMW5PDMH|        Software|world book multim...|         windows mac|\n",
      "| RLXRY2WDMC7F1|        Software|tkt payroll softw...|form print data p...|\n",
      "| RUBVRR7OYC2VG|        Software|step loan modific...|i reviewer indivi...|\n",
      "|R167B987XQ467P|        Software|vector art design...|             exedent|\n",
      "|R31TIOVO2HIPC7|        Software|a love of art cdr...|software time egg...|\n",
      "+--------------+----------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MERGE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_2 = spark.createDataFrame(df_num_2) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the column taht we do not need anymore\n",
    "drop_list = ['review_body'] \n",
    "df = df.select([column for column in df.columns if column not in drop_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+--------------------+\n",
      "|     review_id|product_category|       product_title|\n",
      "+--------------+----------------+--------------------+\n",
      "| RP4MUWMW5PDMH|        Software|world book multim...|\n",
      "| RLXRY2WDMC7F1|        Software|tkt payroll softw...|\n",
      "| RUBVRR7OYC2VG|        Software|step loan modific...|\n",
      "|R167B987XQ467P|        Software|vector art design...|\n",
      "|R31TIOVO2HIPC7|        Software|a love of art cdr...|\n",
      "+--------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df.join(df_num_2, df.review_id == df_num_2.review_id, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stoppp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MODEL PIPELINE**\n",
    "* regexTokenizer: Tokenization (with Regular Expression)\n",
    "* stopwordsRemover: Remove Stop Words\n",
    "* countVectors: Count vectors (document-term vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "# regular expression tokenizer\n",
    "#-------\n",
    "#title \n",
    "#------\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"product_title\", outputCol=\"words\", pattern=\"\\\\W\") #Spliting text into words\n",
    "# stop words\n",
    "add_stopwords = [\"http\",\"https\",\"amp\",\"rt\",\"t\",\"c\",\"the\"] \n",
    "stopwordsRemover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\").setStopWords(add_stopwords) #Removing stop words\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"filtered\", outputCol=\"features_1\", vocabSize=10000, minDF=5) #Converting text into vectors of token counts.\n",
    "#xx =  polarity_txt(x[\"product_title\"])\n",
    "#selector =SelectKBest(chi2, k=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "###-----------\n",
    "# review_body\n",
    "#-------------\n",
    "\n",
    "regexTokenizer_2 = RegexTokenizer(inputCol='review_headline', outputCol=\"words_2\", pattern=\"\\\\W\") \n",
    "# stop words\n",
    "stopwordsRemover_2 = StopWordsRemover(inputCol=\"words_2\", outputCol=\"filtered_2\")\n",
    "# bag of words count\n",
    "countVectors_2 = CountVectorizer(inputCol=\"filtered_2\", outputCol=\"features_2\", vocabSize=10000, minDF=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PIPELINES OF SEVERAL VARIABLES**\n",
    "\n",
    "https://medium.com/@armandj.olivares/a-basic-nlp-tutorial-for-news-multiclass-categorization-82afa6d46aa5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **StringIndexer**\n",
    "StringIndexer encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0.\n",
    "In our case, the label column (Category) will be encoded to label indices, from 0 to 32; the most frequent label (LARCENY/THEFT) will be indexed as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom pyspark.ml.feature import *\\nfrom pyspark.ml import Pipeline\\ntok = Tokenizer(inputCol=\"text\", outputCol=\"words\")\\nhtf = HashingTF(inputCol=\"words\", outputCol=\"tf\", numFeatures=200)\\nw2v = Word2Vec(inputCol=\"text\", outputCol=\"w2v\")\\nohe = OneHotEncoder(inputCol=\"userGroup\", outputCol=\"ug\")\\nva = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"ug\"], outputCol=\"features\")\\npipeline = Pipeline(stages=[tok,htf,w2v,ohe,va])\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from pyspark.ml.feature import *\n",
    "from pyspark.ml import Pipeline\n",
    "tok = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "htf = HashingTF(inputCol=\"words\", outputCol=\"tf\", numFeatures=200)\n",
    "w2v = Word2Vec(inputCol=\"text\", outputCol=\"w2v\")\n",
    "ohe = OneHotEncoder(inputCol=\"userGroup\", outputCol=\"ug\")\n",
    "va = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"ug\"], outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[tok,htf,w2v,ohe,va])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_col = [\"features_1\"]\n",
    "       #, 'title_len', 'title_words', 'title_points', 'title_exc', 'title_int',\n",
    "       #'ratio_spaces_point', 'ratio_len_points', 'title_cd', 'title_th',\n",
    "       #'title_upper_letters', 'title_numbers', 'title_years', 'end_number',\n",
    "       #'starts_number', 'word_sep', 'title_old_version']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "label_stringIdx = StringIndexer(inputCol = \"product_category\", outputCol = \"label\") #Lets encode column of category to a column of category indices\n",
    "va = VectorAssembler(inputCols=fea_col, outputCol=\"features\")\n",
    "pipeline = Pipeline(stages = [regexTokenizer, stopwordsRemover, countVectors,\n",
    "                             label_stringIdx, va])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot recognize a pipeline stage of type <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-03ad9257ca3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the pipeline to training documents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpipelineFit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipelineFit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#dataset.show(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise TypeError(\n\u001b[0;32m---> 97\u001b[0;31m                     \"Cannot recognize a pipeline stage of type %s.\" % type(stage))\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mindexOfLastEstimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot recognize a pipeline stage of type <class 'sklearn.feature_selection.univariate_selection.SelectKBest'>."
     ]
    }
   ],
   "source": [
    "# Fit the pipeline to training documents.\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "#dataset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
    "print(\"Test Dataset Count: \" + str(testData.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(labelCol = 'label', featuresCol = 'features', maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"product_title\",\"product_category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Logistic Regression using TF-IDF Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5) #minDocFreq: remove sparse terms\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, hashingTF, idf, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "lrModel = lr.fit(trainingData)\n",
    "predictions = lrModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"product_title\",\"product_category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regexTokenizer, stopwordsRemover, countVectors, label_stringIdx])\n",
    "pipelineFit = pipeline.fit(df)\n",
    "dataset = pipelineFit.transform(df)\n",
    "(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "# Create ParamGrid for Cross Validation\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.1, 0.3, 0.5]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.2]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(trainingData)\n",
    "\n",
    "predictions = cvModel.transform(testData)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(smoothing=1)\n",
    "model = nb.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"product_title\",\"product_category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \\\n",
    "                            featuresCol=\"features\", \\\n",
    "                            numTrees = 100, \\\n",
    "                            maxDepth = 4, \\\n",
    "                            maxBins = 32)\n",
    "# Train model with Training Data\n",
    "rfModel = rf.fit(trainingData)\n",
    "predictions = rfModel.transform(testData)\n",
    "predictions.filter(predictions['prediction'] == 0) \\\n",
    "    .select(\"product_title\",\"product_category\",\"probability\",\"label\",\"prediction\") \\\n",
    "    .orderBy(\"probability\", ascending=False) \\\n",
    "    .show(n = 10, truncate = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
