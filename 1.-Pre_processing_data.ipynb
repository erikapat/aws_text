{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I checked warnings, but for the final report I prefer ignore those \n",
    "#that really does not affect the results (warnings of libraries, etc)\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my own functions\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils.py_functions import *\n",
    "from utils.cleaning_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud \n",
    "import pandas as pd\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create spark session and provide master as yarn-client and provide application name.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration properties of Apache Spark\n",
    "#sc.stop()\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "APP_NAME = 'pyspark_python'\n",
    "MASTER = 'local[*]'\n",
    "\n",
    "conf = SparkConf().setAppName(APP_NAME)\n",
    "conf = conf.setMaster(MASTER)\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"marketplace\",  StringType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"product_id\",  StringType(), True),\n",
    "    StructField(\"product_parent\", IntegerType(), True),\n",
    "    StructField(\"product_title\", StringType(), True),\n",
    "    StructField(\"product_category\", StringType(), True),\n",
    "    StructField(\"star_rating\", IntegerType(), True),\n",
    "    StructField(\"helpful_votes\", IntegerType(), True),\n",
    "    StructField(\"total_votes\", IntegerType(), True),\n",
    "    StructField(\"vine\", StringType(), True),\n",
    "    StructField(\"verified_purchase\", StringType(), True),\n",
    "    StructField(\"review_headline\", StringType(), True),\n",
    "    StructField(\"review_body\", StringType(), True),\n",
    "    StructField(\"review_date\", StringType(), True)])\n",
    "\n",
    "\n",
    "df_video_games = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Digital_Video_Games_v1_00.tsv')\n",
    "\n",
    "df_software = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Software_v1_00.tsv')\n",
    "\n",
    "df_digital_software = spark.read\\\n",
    "  .format('org.apache.spark.sql.execution.datasources.csv.CSVFileFormat')\\\n",
    "  .option(\"delimiter\",\"\\t\")\\\n",
    "  .option('header', 'true')\\\n",
    "  .option('inferSchema', 'true')\\\n",
    "  .load('data/amazon_reviews_us_Digital_Software_v1_00.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MERGE DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_digital_software.union(df_software);\n",
    "df = df.union(df_video_games);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ELIMINATE DUPLICATED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#duplicated data\n",
    "df_X = df.dropDuplicates(subset= ['product_title', 'product_category', 'product_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>available for windows and mac ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>It say 2015 but the IRS 941 form print out 2014, so you can get data out from program and go to IRS website to print out 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I would like to first address the previous reviewer.  This individual should not be taken seriously  --  why?&lt;br /&gt;1. He did not even buy the product&lt;br /&gt;2. He has a competing product also for s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Exelent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>If you're looking for software that will help you decide where to further invest your time and engery in discovering an era of Western Art, this two-volume set is perfect for that. It will give y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Will not run on my system, which it seems like it should.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Delivered on time and installation was easy.  Still working with the integration with Window Outlook 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Ismok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>This version does not work with Windows 8.1. Very disappointing.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                              review_body\n",
       "0                                                                                                                                                                         available for windows and mac ?\n",
       "1                                                                           It say 2015 but the IRS 941 form print out 2014, so you can get data out from program and go to IRS website to print out 2015\n",
       "2  I would like to first address the previous reviewer.  This individual should not be taken seriously  --  why?<br />1. He did not even buy the product<br />2. He has a competing product also for s...\n",
       "3                                                                                                                                                                                                 Exelent\n",
       "4  If you're looking for software that will help you decide where to further invest your time and engery in discovering an era of Western Art, this two-volume set is perfect for that. It will give y...\n",
       "5                                                                                                                                               Will not run on my system, which it seems like it should.\n",
       "6                                                                                               Delivered on time and installation was easy.  Still working with the integration with Window Outlook 2010\n",
       "7                                                                                                                                                                                                   Ismok\n",
       "8                                                                                                                                        This version does not work with Windows 8.1. Very disappointing."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.set_option('display.max_colwidth', 199) \n",
    "#df_X.select(\"review_body\").toPandas().head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **POLARITY: subjective or objective opinions**\n",
    "\n",
    "* Define the threshold that separates the opinions that are subjective from those that are not. We will consider that for a threshold lower than 0.4 the opinion is not objective.\n",
    "* ELiminate those duplicate products with subjective opinion.\n",
    "* Those objective opinions would be used in `TOPIC MODELLING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLARITY\n",
    "df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], x[\"review_body\"], polarity_txt(x[\"review_body\"])))\n",
    "df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\", \"review_body_pol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|         review_body|    review_body_pol|\n",
      "+--------------------+-------------------+\n",
      "|available for win...|                0.4|\n",
      "|It say 2015 but t...|                0.0|\n",
      "|I would like to f...| 0.1168997668997669|\n",
      "|             Exelent|                0.0|\n",
      "|If you're looking...| 0.3615277777777777|\n",
      "|Will not run on m...|                0.0|\n",
      "|Delivered on time...|0.43333333333333335|\n",
      "|               Ismok|                0.0|\n",
      "|This version does...|              -0.78|\n",
      "|Works great excel...|                0.9|\n",
      "|Very happy with m...| 0.7208333333333334|\n",
      "|download it sever...|0.05555555555555555|\n",
      "|My son enjoyed pl...|            0.04625|\n",
      "|This one of the b...| 0.7333333333333334|\n",
      "|This game is a gr...|          -0.088125|\n",
      "|hey its a grate g...|               -0.4|\n",
      "|I was looking for...|0.11652056277056276|\n",
      "|Great software, I...|                0.8|\n",
      "|I loved it. it wa...|0.24000000000000005|\n",
      "|I ordered the ver...|               -0.1|\n",
      "+--------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'foreach'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-268387fd7a6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"review_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"review_body_pol\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforeach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprintln\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'foreach'"
     ]
    }
   ],
   "source": [
    "df_X.select(\"review_body\", \"review_body_pol\").show().foreach(println)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#So, we eliminate them\n",
    "print(df_X.toPandas().shape)\n",
    "#df_not_dup = df.dropDuplicates(subset= ['product_title', 'product_category', 'product_title'])\n",
    "#print(df.toPandas().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **COMPLETE MISSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.toPandas()\n",
    "#df.review_body.fillna(df.product_title, inplace=True)\n",
    "#df=spark.createDataFrame(df)\n",
    "\n",
    "df.withColumn(\"product_title\",coalesce(df.product_title,df.review_body)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GENERATE NEW FEATURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our list of functions to apply.\n",
    "transform_functions = [\n",
    "    lambda x: len(x),\n",
    "    lambda x: x.count(\" \"),\n",
    "    lambda x: x.count(\".\"),\n",
    "    lambda x: x.count(\"!\"),\n",
    "    lambda x: x.count(\"?\"),\n",
    "    lambda x: len(x) / (x.count(\" \") + 1),\n",
    "    lambda x: x.count(\" \") / (x.count(\".\") + 1),\n",
    "    lambda x: len(re.findall(\"CD|DVD\", x)), # CD \n",
    "    lambda x: len(re.findall(r\"\\d+st|\\d+th|\\d+sd\", x)), # th--> 4th, 5th or 1st or 2sd\n",
    "    lambda x: len(re.findall(\"[A-Z]\", x)), # number of uppercase letters\n",
    "    lambda x: len(re.findall(\"[0-9]\", x)), #numbers\n",
    "    lambda x: len(re.findall(\"\\d{4}\", x)),\n",
    "    lambda x: len(re.findall(\"\\d$\", x)), #end with number\n",
    "    lambda x: len(re.findall(\"^\\d\", x)), #start with number\n",
    "    lambda x: len(re.findall(\"[\\w]+-[\\w]+\",x)), #words separated with -\n",
    "    lambda x: len(re.findall(\"OLD VERSION|Old Version|old version\",x)), #old version\n",
    "]\n",
    "\n",
    "transform_functions_len = [\n",
    "    lambda x: len(x)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_2 = df.toPandas()\n",
    "df_num = df_num_2[['product_title']]\n",
    "df_num_2 = df_num_2[['review_id']]\n",
    "for func in transform_functions:\n",
    "     df_num_2 = pd.concat([df_num_2, df_num['product_title'].apply(func)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num_2.columns = ['review_id', 'title_len', 'title_words', 'title_points',\n",
    "                  'title_exc', 'title_int', 'ratio_spaces_point', 'ratio_len_points', \n",
    "                    'title_cd','title_th', 'title_upper_letters', 'title_numbers',\n",
    "                    'title_years', 'end_number', 'starts_number', 'word_sep', \n",
    "                  'title_old_version']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CLEAN FEATURE: review_body**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **is it an informative feature or nor?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], x[\"review_body\"], polarity_txt(x[\"review_body\"])))\n",
    "df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\", \"review_body_pol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df_product_title = df_X.groupBy([\"product_title\"]).agg(F.count('product_title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_title.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df_X.join(df_product_title, df_X.product_title == df_product_title.product_title, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_title_cleaning(df):\n",
    "    #eliminate contractions I'm -> I am\n",
    "    df_X = df.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], fix_abbreviation(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #consider only noums in the text\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], tag_and_remove(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #lemmatization\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], lemitizeWords(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "\n",
    "    #clean text\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], clean_text(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    #spelling correction\n",
    "    df_X = df_X.rdd.map(lambda x: (x[\"review_id\"], x[\"product_category\"],  x[\"product_title\"], spell_correction(x[\"review_body\"])))\n",
    "    df_X=spark.createDataFrame(df_X, schema = [\"review_id\", \"product_category\", \"product_title\", \"review_body\"])\n",
    "    return df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
